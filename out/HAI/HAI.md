Artificial Intelligence Index Report 2024

# Introduction To The Ai Index Report 2024

Welcome to the seventh edition of the AI Index report. The 2024 Index is our most comprehensive to date and arrives at an important moment when AI's influence on society has never been more pronounced. This year, we have broadened our scope to more extensively cover essential trends such as technical advancements in AI, public perceptions of the technology, and the geopolitical dynamics surrounding its development. Featuring more original data than ever before, this edition introduces new estimates on AI training costs, detailed analyses of the responsible AI landscape, and an entirely new chapter dedicated to AI's impact on science and medicine. The AI Index report tracks, collates, distills, and visualizes data related to artificial intelligence (AI). Our mission is to provide unbiased, rigorously vetted, broadly sourced data in order for policymakers, researchers, executives, journalists, and the general public to develop a more thorough and nuanced understanding of the complex field of AI. The AI Index is recognized globally as one of the most credible and authoritative sources for data and insights on artificial intelligence. Previous editions have been cited in major newspapers, including the The New York Times, Bloomberg, and The Guardian, have amassed hundreds of academic citations, and been referenced by high-level policymakers in the United States, the United Kingdom, and the European Union, among other places. This year's edition surpasses all previous ones in size, scale, and scope, reflecting the growing significance that AI is coming to hold in all of our lives.

2

# Message From The Co-Directors

A decade ago, the best AI systems in the world were unable to classify objects in images at a human level. AI 
struggled with language comprehension and could not solve math problems. Today, AI systems routinely exceed human performance on standard benchmarks. Progress accelerated in 2023. New state-of-the-art systems like GPT-4, Gemini, and Claude 3 are impressively multimodal: They can generate fluent text in dozens of languages, process audio, and even explain memes. As AI has improved, it has increasingly forced its way into our lives. Companies are racing to build AI-based products, and AI is increasingly being used by the general public. But current AI technology still has significant problems. It cannot reliably deal with facts, perform complex reasoning, or explain its conclusions. AI faces two interrelated futures. First, technology continues to improve and is increasingly used, having major consequences for productivity and employment. It can be put to both good and bad uses. In the second future, the adoption of AI is constrained by the limitations of the technology. Regardless of which future unfolds, governments are increasingly concerned. They are stepping in to encourage the upside, such as funding university R&D and incentivizing private investment. Governments are also aiming to manage the potential downsides, such as impacts on employment, privacy concerns, misinformation, and intellectual property rights. As AI rapidly evolves, the AI Index aims to help the AI community, policymakers, business leaders, journalists, and the general public navigate this complex landscape. It provides ongoing, objective snapshots tracking several key areas: technical progress in AI capabilities, the community and investments driving AI development and deployment, public opinion on current and potential future impacts, and policy measures taken to stimulate AI innovation while managing its risks and challenges. By comprehensively monitoring the AI ecosystem, the Index serves as an important resource for understanding this transformative technological force. On the technical front, this year's AI Index reports that the number of new large language models released worldwide in 2023 doubled over the previous year. Two-thirds were open-source, but the highest-performing models came from industry players with closed systems. Gemini Ultra became the first LLM to reach humanlevel performance on the Massive Multitask Language Understanding (MMLU) benchmark; performance on the benchmark has improved by 15 percentage points since last year. Additionally, GPT-4 achieved an impressive 0.96 mean win rate score on the comprehensive Holistic Evaluation of Language Models (HELM) benchmark, which includes MMLU among other evaluations.

3

# Message From The Co-Directors (Cont'D)

Although global private investment in AI decreased for the second consecutive year, investment in generative AI skyrocketed. More Fortune 500 earnings calls mentioned AI than ever before, and new studies show that AI tangibly boosts worker productivity. On the policymaking front, global mentions of AI in legislative proceedings have never been higher. U.S. regulators passed more AI-related regulations in 2023 than ever before. Still, many expressed concerns about AI's ability to generate deepfakes and impact elections. The public became more aware of AI, and studies suggest that they responded with nervousness. Ray Perrault and Jack Clark Co-directors, AI Index 4

![4_image_0.png](4_image_0.png)

# Top 10 Takeaways

1. AI beats humans on some tasks, but not on all. AI has surpassed human performance on several benchmarks, including some in image classification, visual reasoning, and English understanding. Yet it trails behind on more complex tasks like competition-level mathematics, visual commonsense reasoning and planning.

2. Industry continues to dominate frontier AI research. In 2023, industry produced 51 notable machine learning models, while academia contributed only 15. There were also 21 notable models resulting from industry-academia collaborations in 2023, a new high.

3. Frontier models get way more expensive. According to AI Index estimates, the training costs of state-of-the-art AI models have reached unprecedented levels. For example, OpenAI's GPT-4 used an estimated $78 million worth of compute to train, while Google's Gemini Ultra cost $191 million for compute.

4. The United States leads China, the EU, and the U.K. as the leading source of top AI models. In 2023, 61 notable AI models originated from U.S.-based institutions, far outpacing the European Union's 21 and China's 15. 

5. Robust and standardized evaluations for LLM responsibility are seriously lacking. 

New research from the AI Index reveals a significant lack of standardization in responsible AI reporting. Leading developers, including OpenAI, Google, and Anthropic, primarily test their models against different responsible AI benchmarks. This practice complicates efforts to systematically compare the risks and limitations of top AI models.

6. Generative AI investment skyrockets. Despite a decline in overall AI private investment last year, funding for generative AI surged, nearly octupling from 2022 to reach $25.2 billion. Major players in the generative AI space, including OpenAI, Anthropic, Hugging Face, and Inflection, reported substantial fundraising rounds.

7. The data is in: AI makes workers more productive and leads to higher quality work. In 2023, several studies assessed AI's impact on labor, suggesting that AI enables workers to complete tasks more quickly and to improve the quality of their output. These studies also demonstrated AI's potential to bridge the skill gap between low- and high-skilled workers. Still, other studies caution that using AI without proper oversight can lead to diminished performance. 

5 5

# Top 10 Takeaways (Cont'D)

8. Scientific progress accelerates even further, thanks to AI. In 2022, AI began to advance scientific discovery. 2023, however, saw the launch of even more significant science-related AI applicationsfrom AlphaDev, which makes algorithmic sorting more efficient, to GNoME, which facilitates the process of materials discovery.

9. The number of AI regulations in the United States sharply increases. The number of AI-
related regulations in the U.S. has risen significantly in the past year and over the last five years. In 2023, there were 25 AI-related regulations, up from just one in 2016. Last year alone, the total number of AI-related regulations grew by 56.3%.

10. People across the globe are more cognizant of AI's potential impactâ€”and more nervous. 

A survey from Ipsos shows that, over the last year, the proportion of those who think AI will dramatically affect their lives in the next three to five years has increased from 60% to 66%. Moreover, 52% express nervousness toward AI products and services, marking a 13 percentage point rise from 2022. In America, Pew data suggests that 52% of Americans report feeling more concerned than excited about AI, rising from 37% in 2022.

# Steering Committee

## Co-Directors

Jack Clark, Anthropic, OECD Raymond Perrault, SRI International

## Members

Erik Brynjolfsson, Stanford University John Etchemendy, Stanford University Katrina Ligett, Hebrew University Terah Lyons, JPMorgan Chase & Co. James Manyika, Google, University of Oxford Juan Carlos Niebles, Stanford University, Salesforce Vanessa Parli, Stanford University Yoav Shoham, Stanford University, AI21 Labs Russell Wald, Stanford University

## Staff And Researchers Research Manager And Editor In Chief

Nestor Maslej Stanford University

## Research Associate

Loredana Fattorini Stanford University

## Affiliated Researchers

Elif Kiesow Cortez, Stanford Law School Research Fellow Anka Reuel, Stanford University Robi Rahman, Data Scientist

## Graduate Researchers

James da Costa, Stanford University Simba Jonga, Stanford University

## Undergraduate Researchers

Emily Capstick, Stanford University Summer Flowers, Stanford University Armin Hamrah, Claremont McKenna College Amelia Hardy, Stanford University Mena Hassan, Stanford University Ethan Duncan He-Li Hellman, Stanford University Alexandra Rome, Freelance Researcher Lapo Santarlasci, IMT School for Advanced Studies Lucca Julia Betts Lotufo, Stanford University Sukrut Oak, Stanford University Andrew Shi, Stanford University Jason Shin, Stanford University Emma Williamson, Stanford University Alfred Yu, Stanford University

## How To Cite This Report

Nestor Maslej, Loredana Fattorini, Raymond Perrault, Vanessa Parli, Anka Reuel, Erik Brynjolfsson, John Etchemendy, Katrina Ligett, Terah Lyons, James Manyika, Juan Carlos Niebles, Yoav Shoham, Russell Wald, and Jack Clark, "The AI Index 2024 Annual Report," AI Index Steering Committee, Institute for Human-Centered AI, Stanford University, Stanford, CA, April 2024. The AI Index 2024 Annual Report by Stanford University is licensed under Attribution-NoDerivatives 4.0 International.

## Public Data And Tools

The AI Index 2024 Report is supplemented by raw data and an interactive tool. We invite each reader to use the data and the tool in a way most relevant to their work and interests.

- Raw data and charts: The public data and high-resolution images of all the charts in the report are available on Google Drive.

- Global AI Vibrancy Tool: Compare the AI ecosystems of over 30 countries. The Global AI Vibrancy tool will be updated in the summer of 2024.

## Ai Index And Stanford Hai

The AI Index is an independent initiative at the Stanford Institute for Human-Centered Artificial Intelligence (HAI).

![7_image_0.png](7_image_0.png) The AI Index was conceived within the One Hundred Year Study on Artificial Intelligence (AI100). 

![7_image_1.png](7_image_1.png) The AI Index welcomes feedback and new ideas for next year. Contact us at AI-Index-Report@stanford.edu. The AI Index acknowledges that while authored by a team of human researchers, its writing process was aided by AI tools. Specifically, the authors used ChatGPT and Claude to help tighten and copy edit initial drafts. The workflow involved authors writing the original copy, then utilizing AI tools as part of the editing process.

8

# Supporting Partners

Google MOpenAI
ould anthropy

![8_image_0.png](8_image_0.png)

Analytics and Research Partners Center for accenture Research on Foundation omputing Researc Models sociation IFR
5 EPOCHAI GitHub Agovini International Federation of Robotics EMERGING TECHNOLOGY
Ø·Ù„ Lightcast    Linked in McKinsey INFORMATICS

![8_image_1.png](8_image_1.png)

& Company

![8_image_2.png](8_image_2.png)

PEARL
POLICY, ELECTIONS &
REPRESENTATION LAR
munk school T 

![9_image_0.png](9_image_0.png)

# Contributors

The AI Index wants to acknowledge the following individuals by chapter and section for their contributions of data, analysis, advice, and expert commentary included in the AI Index 2024 Report:

## Introduction

Loredana Fattorini, Nestor Maslej, Vanessa Parli, Ray Perrault

## Chapter 1: Research And Development

Catherine Aiken, Terry Auricchio, Tamay Besiroglu, Rishi Bommasani, Andrew Brown, Peter Cihon, James da Costa, Ben Cottier, James Cussens, James Dunham, Meredith Ellison, Loredana Fattorini, Enrico Gerding, Anson Ho, Percy Liang, Nestor Maslej, Greg Mori, Tristan Naumann, Vanessa Parli, Pavlos Peppas, Ray Perrault, Robi Rahman, Vesna Sablijakovic-Fritz, Jim Schmiedeler, Jaime Sevilla, Autumn Toney, Kevin Xu, Meg Young, Milena Zeithamlova

## Chapter 2: Technical Performance

Rishi Bommasani, Emma Brunskill, Erik Brynjolfsson, Emily Capstick, Jack Clark, Loredana Fattorini, Tobi Gertsenberg, Noah Goodman, Nicholas Haber, Sanmi Koyejo, Percy Liang, Katrina Ligett, Sasha Luccioni, Nestor Maslej, Juan Carlos Niebles, Sukrut Oak, Vanessa Parli, Ray Perrault, Andrew Shi, Yoav Shoham, Emma Williamson

## Chapter 3: Responsible Ai

Jack Clark, Loredana Fattorini, Amelia Hardy, Katrina Ligett, Nestor Maslej, Vanessa Parli, Ray Perrault, Anka Reuel, Andrew Shi

## Chapter 4: Economy

Susanne Bieller, Erik Brynjolfsson, Mar Carpanelli, James da Costa, Natalia Dorogi, Heather English, Murat Erer, Loredana Fattorini, Akash Kaura, James Manyika, Nestor Maslej, Cal McKeever, Julia Nitschke, Layla O'Kane, Vanessa Parli, Ray Perrault, Brittany Presten, Carl Shan, Bill Valle, Casey Weston, Emma Williamson

## Chapter 5: Science And Medicine

Russ Altman, Loredana Fattorini, Remi Lam, Curtis Langlotz, James Manyika, Nestor Maslej, Vanessa Parli, Ray Perrault, Emma Williamson